# -*- coding: utf-8 -*-
"""ingest_nyc.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1W2-FLLeoKS6uOx1nwxfQYqHOhdhoX3cO
"""

import os
import requests
import pandas as pd

def ensure_dir(directory):
    if not os.path.exists(directory):
        os.makedirs(directory)

DATA_DIR = os.path.join("..", "data_raw", "nyc")
# Example: NYC 311 Service Requests dataset (as CSV)
NYC_311_URL = "https://data.cityofnewyork.us/resource/erm2-nwe9.csv?$limit=50000"

def download_nyc_311(limit=50000):
    ensure_dir(DATA_DIR)
    url = NYC_311_URL.replace("50000", str(limit))
    print("Downloading NYC 311 dataset (limit={})".format(limit))
    resp = requests.get(url)
    resp.raise_for_status()
    out_path = os.path.join(DATA_DIR, "nyc_311.csv")
    with open(out_path, "wb") as f:
        f.write(resp.content)
    print("Saved to", out_path)
    return out_path

def load_nyc_311(csv_path=None):
    if csv_path is None:
        csv_path = os.path.join(DATA_DIR, "nyc_311.csv")
    df = pd.read_csv(csv_path, low_memory=False)
    print(f"Loaded {len(df)} records from NYC 311 data.")
    return df

if __name__ == "__main__":
    path = download_nyc_311(limit=50000)
    df = load_nyc_311(path)
    print(df.columns.tolist())
    print(df.head())

print("Missing values before cleaning:")
display(df.isnull().sum())

threshold = len(df) * 0.5
df_cleaned = df.dropna(axis=1, thresh=threshold)
print(f"Dropped {df.shape[1] - df_cleaned.shape[1]} columns with more than 50% missing values.")
df = df_cleaned.copy()

print("Missing values after dropping columns with >50% nulls:")
display(df.isnull().sum())